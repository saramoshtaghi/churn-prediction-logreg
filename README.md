# Customer Churn Prediction Project

## ğŸ“Œ Project Overview
This project focuses on predicting customer churn using Logistic Regression. It includes two versions:
1. **Without SMOTE** - The model is trained on the original imbalanced dataset.
2. **With SMOTE** - The model is trained using SMOTE (Synthetic Minority Over-sampling Technique) to balance the dataset.

The project evaluates both models at multiple decision thresholds (0.2, 0.3, 0.4, 0.5) and compares their performance using:
- **Confusion Matrix**
- **Precision, Recall, F1-score**
- **ROC-AUC Curve**

---

## ğŸ“‚ Folder Structure
```
/customer_churn_project/
â”‚â”€â”€ /models/                 # Saved trained models
â”‚   â”œâ”€â”€ logistic_regression_no_smot.pkl
â”‚   â”œâ”€â”€ logistic_regression_with_smot.pkl
â”‚   â”œâ”€â”€ scaler.pkl
â”‚â”€â”€ /src/                    # Source code for training and evaluation
â”‚   â”œâ”€â”€ train.py              # Training script (handles both SMOTE and no-SMOTE versions)
â”‚   â”œâ”€â”€ eval.py               # Evaluation script for both models
â”‚â”€â”€ /data/                    # Dataset storage
â”‚   â”œâ”€â”€ customer_churn.csv    # Raw dataset
â”‚â”€â”€ README.md                 # Project documentation
â”‚â”€â”€ requirements.txt          # Dependencies list
â”‚â”€â”€ LICENSE                   # License file
```

---

## ğŸš€ Installation & Setup

### **1ï¸âƒ£ Clone the Repository**
```bash
git clone https://github.com/your-username/customer_churn_project.git
cd customer_churn_project
```

### **2ï¸âƒ£ Install Dependencies**
```bash
pip install -r requirements.txt
```

### **3ï¸âƒ£ Preprocess Data**
- The script **automatically handles missing values** and scales numerical features using `StandardScaler`.
- SMOTE is applied in the training phase **only when specified**.

---

## ğŸ¯ Model Training
Run the training script to generate models:
```bash
python src/train.py --use_smot  # Runs training with SMOTE
python src/train.py  # Runs training without SMOTE
```
- The trained models and scalers are saved in the `/models/` directory.

---

## ğŸ“Š Model Evaluation
To evaluate and compare models at different thresholds (0.2, 0.3, 0.4, 0.5):
```bash
python src/eval.py
```
This script computes:
- **Accuracy, Precision, Recall, F1-score**
- **ROC-AUC Score**
- **Plots ROC Curves**

---


## ğŸ“© Contributing
Feel free to submit PRs or open issues. For discussions, reach out via **sarahmoshtaq@gmail.com**.

---

## ğŸ“œ License
This project is open-source under the MIT License. See **LICENSE** for details.

---

**ğŸš€ Happy Coding!**

