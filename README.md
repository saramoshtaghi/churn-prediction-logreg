# Customer Churn Prediction Project

## ğŸ“Œ Project Overview
This project focuses on predicting customer churn using Logistic Regression. It includes two versions:
1. **Without SMOTE** - The model is trained on the original imbalanced dataset.
2. **With SMOTE** - The model is trained using SMOTE (Synthetic Minority Over-sampling Technique) to balance the dataset.

Both versions allow for threshold tuning to optimize recall and precision.

---

## ğŸ“‚ Folder Structure
```
/customer_churn_project/
â”‚â”€â”€ /models/                 # Saved trained models
â”‚   â”œâ”€â”€ logistic_regression_no_smot.pkl
â”‚   â”œâ”€â”€ logistic_regression_with_smot.pkl
â”‚   â”œâ”€â”€ scaler_no_smot.pkl
â”‚   â”œâ”€â”€ scaler_with_smot.pkl
â”‚â”€â”€ /src/                    # Source code for training and evaluation
â”‚   â”œâ”€â”€ train_no_smot.py      # Training script without SMOTE
â”‚   â”œâ”€â”€ train_with_smot.py    # Training script with SMOTE
â”‚   â”œâ”€â”€ evaluate_model.py     # Evaluation script
â”‚â”€â”€ /data/                    # Dataset storage
â”‚   â”œâ”€â”€ customer_churn.csv    # Raw dataset
â”‚â”€â”€ README.md                 # Project documentation
```

---

## ğŸš€ Installation & Setup

### **1ï¸âƒ£ Clone the Repository**
```bash
git clone https://github.com/your-username/customer_churn_project.git
cd customer_churn_project
```

### **2ï¸âƒ£ Install Dependencies**
```bash
pip install -r requirements.txt
```

### **3ï¸âƒ£ Train the Model**
#### **Without SMOTE**
```bash
python src/train_no_smot.py
```
#### **With SMOTE**
```bash
python src/train_with_smot.py
```

### **4ï¸âƒ£ Evaluate the Model**
```bash
python src/evaluate_model.py
```

---

## ğŸ” Model Training Details
- **`train_no_smot.py`**: Trains a Logistic Regression model on the original dataset.
- **`train_with_smot.py`**: Applies SMOTE to balance the dataset before training.
- **Hyperparameters:** C=1.0, solver='liblinear'
- **Feature Scaling:** StandardScaler applied to numeric features.
- **Decision Threshold Adjustment:** Threshold tuning for optimizing Precision vs. Recall.

---

## ğŸ“Š Model Evaluation
We evaluate both models using:
- **Accuracy**
- **Precision, Recall, F1-score**
- **ROC-AUC Curve**
- **Confusion Matrix Analysis**

### **Compare Performance**
| Model | Precision | Recall | F1-score |
|--------|------------|---------|----------|
| No SMOTE | High Precision, Low Recall | More False Negatives | Balanced |
| With SMOTE | Lower Precision, Higher Recall | Captures More Churners | Higher Recall |

**Choosing the Model:**
- If you care more about **capturing churners**, use **With SMOTE** (higher recall).
- If you want fewer **false churn alerts**, use **Without SMOTE** (higher precision).

---

## ğŸ”¥ Next Steps
- [ ] Experiment with **other models** (Random Forest, XGBoost).
- [ ] Tune **decision thresholds dynamically**.
- [ ] Deploy as a **Flask API or Streamlit app**.

---

## ğŸ“© Contributing
Feel free to submit PRs or open issues. For discussions, reach out via **sarahmoshtaq@gmail.com**.

---

## ğŸ“œ License
This project is open-source under the MIT License. See **LICENSE** for details.

---

**ğŸš€ Happy Coding!**

